{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering/Cleaning data based on language using FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>FastText</b> : https://fasttext.cc/docs/en/language-identification.html\n",
    "\n",
    "    FastText is an facebooks's open-source, free, lightweight library that allows users to learn text representations and text classifiers. It works on standard, generic hardware. Models can later be reduced in size to even fit on mobile devices.\n",
    "    \n",
    "Model download (lid.176.ftz) : https://s3-us-west-1.amazonaws.com/fasttext-vectors/supervised_models/lid.176.ftz\n",
    "\n",
    "<b> Python Binding Installation: </b>  https://github.com/vrasneur/pyfasttext\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyfasttext import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastText(\"lid.176.ftz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u><b> Supported Languages: </b></u>\n",
    "\n",
    "af als am an ar arz as ast av az azb ba bar bcl be bg bh bn bo bpy br bs bxr ca cbk ce ceb ckb co cs cv cy da de diq dsb dty dv el eml en eo es et eu fa fi fr frr fy ga gd gl gn gom gu gv he hi hif hr hsb ht hu hy ia id ie ilo io is it ja jbo jv ka kk km kn ko krc ku kv kw ky la lb lez li lmo lo lrc lt lv mai mg mhr min mk ml mn mr mrj ms mt mwl my myv mzn nah nap nds ne new nl nn no oc or os pa pam pfl pl pms pnb ps pt qu rm ro ru rue sa sah sc scn sco sd sh si sk sl so sq sr su sv sw ta te tg th tk tl tr tt tyv ug uk ur uz vec vep vi vls vo wa war wuu xal xmf yi yo yue zh\n",
    "\n",
    "<b> Language codes: </b> https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentence_language(sentence, n_nearest_language = 5):\n",
    "    if sentence != \"\":\n",
    "        return model.predict_proba_single(sentence,n_nearest_language)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('en', 0.9650917056298861), ('hi', 0.0027506044766796153)]\n"
     ]
    }
   ],
   "source": [
    "print(predict_sentence_language(\"hi this is language identification\",2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_document(document, language_to_be_kept = ['en'], min_freq_filtering = 0.5, sentence_delimiter ='.', as_list =0):\n",
    "    \n",
    "    result_document = []\n",
    "    document_split = document.strip().split(sentence_delimiter)\n",
    "    \n",
    "    for sentence in document_split:\n",
    "        \n",
    "        pred_res = predict_sentence_language(sentence, 1)\n",
    "        \n",
    "        if(len(pred_res) > 0):\n",
    "            if(([l for l in language_to_be_kept if pred_res[0][0] in l]) \n",
    "               and (pred_res[0][1] > min_freq_filtering)):\n",
    "                result_document.append(sentence)\n",
    "    if(as_list == 0):            \n",
    "        return \".\".join(result_document)\n",
    "    else:\n",
    "        return result_document\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi this is a verification check. should give me these two sentences\n"
     ]
    }
   ],
   "source": [
    "print(clean_document(\"hi this is a verification check. should give me these two sentences. cette phrase devrait être supprimée\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> clean_document :</b>\n",
    "<table style=\"width: 100%; align='center'\" border=\"1\">\n",
    "    <tr><th>Parameter Name </th><th>Description</th><th>Default</th> </tr> \n",
    "    <tr><td>document</td><td>data as a string/blob</td><td>None</td> </tr>\n",
    "    <tr><td>language_to_be_kept</td><td>python list of languages not to be removed</td><td>['en']</td> </tr>\n",
    "    <tr><td>min_freq_filtering</td><td>minimum match to be selected [0.0-1.0]</td><td>0.5</td> </tr>\n",
    "    <tr><td>sentence_delimiter</td><td>split the document</td><td>'.' {dot}</td> </tr>\n",
    "    <tr><td>as_list</td><td>return result as list [0=as blob /1=as list]</td><td>0</td> </tr>\n",
    "</table> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===================================================================\n",
    "\n",
    "To do:\n",
    "    1. Variable cutoff of each selected languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
